{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSc7AU66mJSC"
      },
      "source": [
        "##### Copyright 2025 Patrick Loeber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "tc6tjo9vmJSE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuC_VSKMcEt6"
      },
      "source": [
        "# Workshop: Build with Gemini (Part 1)\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-1-text-prompting.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This workshop teaches how to build with Gemini using the Gemini API and Python SDK.\n",
        "\n",
        "Course outline:\n",
        "\n",
        "- **Part1 (this notebook): Quickstart + Text prompting**\n",
        "  - Text understanding\n",
        "  - Streaming response\n",
        "  - Chats\n",
        "  - System prompts\n",
        "  - Config options\n",
        "  - Long context\n",
        "  - Token usage\n",
        "  - Final excercise: Chat with book\n",
        "\n",
        "- **[Part 2: Multimodal understanding (image, video, audio, docs, code)](https://github.com/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-2-multimodal-understanding.ipynb)**\n",
        "\n",
        "- **[Part 3: Thinking models + agentic capabilities (tool usage)](https://github.com/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-3-thinking-and-tools.ipynb)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avRVsnMMJvof"
      },
      "source": [
        "## 0. Use the Google AI Studio as playground\n",
        "\n",
        "Explore and play with all models in the [Google AI Studio](https://aistudio.google.com/apikey).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnl6q8tMcpwU"
      },
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD1kaBP4dnZG"
      },
      "source": [
        "Get a free API key in the [Google AI Studio](https://aistudio.google.com/apikey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "j6raUs82eYfk"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKjUEGGzdp87"
      },
      "source": [
        "Install the [Google Gen AI Python SDK](https://github.com/googleapis/python-genai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Y4d9NjqNeAXx"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6b7d1FleDuz"
      },
      "source": [
        "Configure Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "o6Uort3heUqT"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P2KmoPSgRxO"
      },
      "source": [
        "Configure model. See all [models](https://ai.google.dev/gemini-api/docs/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "0qcgiiP7gO-6"
      },
      "outputs": [],
      "source": [
        "MODEL = \"gemini-2.0-flash-lite\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLsGbeGec8iF"
      },
      "source": [
        "## 2. Send your first prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "e57RFdZ6dRro",
        "outputId": "7fd5e162-e400-458b-94ab-bdf29e94a5ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's break down Bayesian Inference and Data Assimilation. They are closely related concepts, especially in fields that deal with modeling real-world systems.\n",
            "\n",
            "**1. Bayesian Inference: Updating Beliefs with Evidence**\n",
            "\n",
            "At its core, Bayesian Inference is a method for updating our beliefs about something (a hypothesis, a parameter, a model) in light of new evidence (data).  It's based on **Bayes' Theorem**, a mathematical formula that formalizes how we should rationally update our beliefs.\n",
            "\n",
            "**Key Concepts:**\n",
            "\n",
            "*   **Prior Belief (Prior Probability):**  This represents our initial belief about something *before* we see any new data. It's a probability distribution that expresses our uncertainty or existing knowledge.  Think of it as our \"educated guess\" or starting point. For example, you might have a prior belief about the average rainfall in a region based on historical trends or climatological understanding.\n",
            "\n",
            "*   **Likelihood:** This is the probability of observing the data we *actually* observed, *given* a specific value of the thing we're trying to estimate.  In other words, it tells us how well a particular hypothesis or parameter explains the data.  If we're estimating rainfall, the likelihood would tell us how likely it is to observe the rainfall measurements we took, given a particular average rainfall value.  A high likelihood means the data is consistent with the hypothesis.\n",
            "\n",
            "*   **Posterior Belief (Posterior Probability):** This is our updated belief about the thing we're estimating *after* considering the data. It's the result of combining the prior belief and the likelihood.  It's what we're ultimately interested in.  It represents a more informed and refined understanding, incorporating the information from the data.\n",
            "\n",
            "*   **Bayes' Theorem Formula:**\n",
            "\n",
            "    ```\n",
            "    P(A|B) = [P(B|A) * P(A)] / P(B)\n",
            "    ```\n",
            "\n",
            "    Where:\n",
            "\n",
            "    *   `P(A|B)` is the **Posterior probability** of event A happening given that event B has occurred (our updated belief).\n",
            "    *   `P(B|A)` is the **Likelihood** of event B happening given that event A has occurred (how well the hypothesis explains the data).\n",
            "    *   `P(A)` is the **Prior probability** of event A happening (our initial belief).\n",
            "    *   `P(B)` is the **Marginal likelihood** or evidence. It's the probability of observing the data under any possible hypothesis and acts as a normalizing constant. Calculating this can be computationally challenging.\n",
            "\n",
            "**Analogy:**\n",
            "\n",
            "Imagine you're trying to guess whether a coin is fair or biased.\n",
            "\n",
            "*   **Prior:** You might start with a prior belief that the coin is equally likely to be fair (50% chance heads) or biased towards heads (say, 80% chance heads).\n",
            "*   **Data:** You flip the coin 10 times and get 7 heads.\n",
            "*   **Likelihood:** You calculate how likely it is to get 7 heads out of 10 flips if the coin is fair versus if it's biased towards heads.\n",
            "*   **Posterior:** Bayes' Theorem combines your prior belief and the likelihood to give you a new, updated belief about the probability that the coin is fair or biased, given the observed data.  The posterior probability would likely shift towards believing the coin is biased, but how much it shifts depends on the strength of your initial prior and the strength of the data (i.e., if you only flipped the coin twice and got two heads, you wouldn't be as confident in the bias).\n",
            "\n",
            "**Key Advantages of Bayesian Inference:**\n",
            "\n",
            "*   **Incorporates Prior Knowledge:**  Leverages existing knowledge or assumptions.\n",
            "*   **Quantifies Uncertainty:** Provides a probability distribution (the posterior) that represents the uncertainty in our estimates.\n",
            "*   **Sequential Updating:** Can be used to update beliefs as new data becomes available.\n",
            "*   **Naturally Handles Missing Data:** Can handle cases where some data is missing.\n",
            "\n",
            "**2. Data Assimilation: Combining Models and Observations**\n",
            "\n",
            "Data Assimilation (DA) is a technique used to improve the accuracy of mathematical models by incorporating observational data.  It's particularly important in fields like weather forecasting, oceanography, climate modeling, and reservoir engineering where models are complex and inherently uncertain, and observations are often sparse and noisy.  In essence, DA is a sophisticated application of Bayesian Inference.\n",
            "\n",
            "**Key Concepts:**\n",
            "\n",
            "*   **Model:**  A mathematical representation of a physical system (e.g., a weather model, an ocean circulation model). These models are based on physical laws and equations, but they are always approximations of reality.  They evolve a state vector *x* forward in time.  Think of the model as a \"prediction engine.\"\n",
            "\n",
            "*   **Observations (Measurements):** Real-world data collected from sensors, instruments, or other sources (e.g., weather stations, satellites, buoys). These observations are typically noisy and incomplete.  They are typically represented by a vector *y*.\n",
            "\n",
            "*   **Analysis:** The process of combining the model forecast (prior) with the observations to produce an improved estimate of the system's state (posterior). This improved estimate is often called the \"analysis.\"  The analysis is the \"best guess\" of the system's state, given both the model and the observations.\n",
            "\n",
            "*   **Data Assimilation Algorithm:**  A specific mathematical algorithm used to perform the analysis.  Common DA algorithms include:\n",
            "    *   **Optimal Interpolation (OI):** A relatively simple method that uses a weighted average of the model forecast and observations.\n",
            "    *   **Kalman Filter (KF):**  A more sophisticated method that assumes that the model and observations are Gaussian distributed.  It recursively updates the state estimate based on new observations.  Many variants exist, such as the Extended Kalman Filter (EKF) and the Ensemble Kalman Filter (EnKF), which are used for non-linear models.\n",
            "    *   **Variational Methods (e.g., 3D-Var, 4D-Var):**  These methods formulate the data assimilation problem as an optimization problem, where the goal is to find the model state that best fits both the model equations and the observations over a time window.\n",
            "\n",
            "**How Data Assimilation Works (Simplified):**\n",
            "\n",
            "1.  **Forecast:** The model is run forward in time to produce a forecast of the system's state at a particular time. This forecast represents our \"prior\" estimate.\n",
            "2.  **Observations:** New observations of the system are collected.\n",
            "3.  **Analysis:** The data assimilation algorithm combines the model forecast and the observations to produce an improved estimate of the system's state (the \"analysis\"). This is the \"posterior\" estimate.  The algorithm takes into account the uncertainties in both the model and the observations (represented by error covariance matrices).\n",
            "4.  **Update:** The analysis becomes the new initial condition for the model, and the process is repeated for the next time step.\n",
            "\n",
            "**Data Assimilation as Bayesian Inference:**\n",
            "\n",
            "DA is fundamentally Bayesian Inference applied to a time-evolving system:\n",
            "\n",
            "*   **Prior:** The model forecast is the prior belief about the system's state.\n",
            "*   **Likelihood:** The observations and their associated error statistics define the likelihood function.  It describes how likely the observations are, given a particular model state.\n",
            "*   **Posterior:** The analysis is the posterior distribution of the system's state, given the model forecast and the observations.  It represents our best estimate after combining the prior knowledge (the model) with the evidence (the observations).\n",
            "\n",
            "**Example: Weather Forecasting**\n",
            "\n",
            "1.  **Model:** A numerical weather prediction model is used to forecast temperature, wind, and other weather variables.\n",
            "2.  **Observations:** Weather observations from satellites, weather stations, and other sources are collected.\n",
            "3.  **Data Assimilation:** A data assimilation algorithm (e.g., an Ensemble Kalman Filter) combines the model forecast with the observations to create an improved estimate of the current weather conditions (the \"analysis\").\n",
            "4.  **Next Forecast:** The analysis is used as the initial condition for the next weather forecast.\n",
            "\n",
            "**Benefits of Data Assimilation:**\n",
            "\n",
            "*   **Improved Accuracy:** DA can significantly improve the accuracy of model forecasts.\n",
            "*   **Reduced Uncertainty:** DA can reduce the uncertainty in model estimates.\n",
            "*   **Initialization of Models:** DA provides a consistent and accurate initial state for models.\n",
            "*   **State Estimation:** DA provides estimates of the system's state at regular intervals.\n",
            "*   **Parameter Estimation:** Can be used to estimate unknown parameters within a model.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "*   **Bayesian Inference:** A general framework for updating beliefs in light of new evidence, based on Bayes' Theorem.\n",
            "*   **Data Assimilation:** A specific application of Bayesian Inference to combine mathematical models with observational data to improve the accuracy of the models, particularly in time-evolving systems. Data assimilation is how we make sure our weather forecasts are as accurate as possible, given the complexity of the atmosphere and the limitations of our models and measurements.\n",
            "\n",
            "I hope this explanation clarifies the concepts of Bayesian Inference and Data Assimilation!  Let me know if you have any further questions.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=\"Explain Bayesian Inference and Data Assimilation\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rfjqevtmRBO"
      },
      "source": [
        "#### **!! Exercise !!**\n",
        "- Send a few more prompts\n",
        "  - Tell Gemini to write a blog post about the transformers architecture\n",
        "  - Ask Gemini to explain list comprehension in Python\n",
        "- Experiment with models:\n",
        "  - Try Gemini 2.0 Flash-Lite\n",
        "  - Try Gemini 2.5 Pro Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Zj8kiIoRqn"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHqnTYJFdSlG"
      },
      "source": [
        "## 3. Text understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHRVaK0-tCE_"
      },
      "source": [
        "The simplest way to generate text is to provide the model with a text-only prompt. `contents` can be a single prompt, a list of prompts, or a combination of multimodal inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_HqjSiFsUQ2"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itCzXz1BiG5g"
      },
      "source": [
        "#### Streaming response\n",
        "\n",
        "By default, the model returns a response after completing the entire text generation process. You can achieve faster interactions by using streaming to return outputs as they're generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d6HzwfZdWbt"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZjfCkzSdcEc"
      },
      "source": [
        "#### Chat\n",
        "\n",
        "The SDK chat class provides an interface to keep track of conversation history. Behind the scenes it uses the same `generate_content` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "BCI8O9Ldjn6q",
        "outputId": "e89025ba-a226-4689-b40a-33ba8d93af2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I do not have access to live, real-time information, including weather updates. To find out the weather in Berlin today, I recommend checking a reliable weather app or website like:\n",
            "\n",
            "*   **AccuWeather:** [https://www.accuweather.com/en/de/berlin/10178/weather-forecast/178087](https://www.accuweather.com/en/de/berlin/10178/weather-forecast/178087)\n",
            "*   **The Weather Channel:** [https://weather.com/en-US/weather/today/l/GMXX0007:1:GM](https://weather.com/en-US/weather/today/l/GMXX0007:1:GM)\n",
            "*   **Google Weather:** Simply search \"weather in Berlin\" on Google.\n",
            "\n",
            "These sources will give you the most up-to-date forecast.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "\n",
        "chat = client.chats.create(model=MODEL)\n",
        "\n",
        "response = chat.send_message(\"Hi, How's the weather today in Berlin\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmfMuI44Kev2"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_MkOG6uLs75"
      },
      "source": [
        "#### Parameters\n",
        "\n",
        "Every prompt you send to the model includes parameters that control how the model generates responses. You can configure these parameters, or let the model use the default options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "J_jk93Z-Lum-",
        "outputId": "363c0e3d-597d-48d9-b1cc-9d125b4ff8c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Bridging the Gap Between Models and Reality: A Deep Dive into Bayesian Data Assimilation\n",
            "\n",
            "We live in a world of complex systems, from weather patterns to financial markets. Understanding and predicting these systems requires building mathematical models, but these models are always imperfect. Enter **Bayesian Data Assimilation (BDA)**, a powerful technique that elegantly combines model predictions with real-world observations to produce a more accurate and reliable estimate of the system's state.\n",
            "\n",
            "Think of it like this: your model is your best guess, but your observations are the ground truth. BDA provides the framework to intelligently merge these two sources of information, leaning on each where appropriate.\n",
            "\n",
            "**So, what exactly *is* Bayesian Data Assimilation?**\n",
            "\n",
            "At its core, BDA is a statistical technique based on **Bayes' Theorem**. This theorem provides a way to update our beliefs about a system (our *prior knowledge* or model prediction) given new evidence (observations). In the context of data assimilation:\n",
            "\n",
            "*   **Prior:** The model prediction of the system's state at a given time. This is your initial guess, based on your understanding of the system's dynamics.\n",
            "*   **Likelihood:**  Represents how well the observations agree with the model prediction. It quantifies the probability of observing the actual data, given a particular state. It also accounts for the inherent errors in both the model and the observations.\n",
            "*   **Posterior:** The updated estimate of the system's state, after combining the prior and the likelihood. This is your best estimate, informed by both the model and the observations.\n",
            "\n",
            "**Bayes' Theorem in Action:**\n",
            "\n",
            "Mathematically, this looks like:\n",
            "\n",
            "```\n",
            "P(State | Observations) = [P(Observations | State) * P(State)] / P(Observations)\n",
            "```\n",
            "\n",
            "Where:\n",
            "\n",
            "*   `P(State | Observations)` is the **Posterior** probability of the state given the observations.\n",
            "*   `P(Observations | State)` is the **Likelihood** of observing the data given a particular state.\n",
            "*   `P(State)` is the **Prior** probability of the state (model prediction).\n",
            "*   `P(Observations)` is the probability of observing the data (a normalizing constant).\n",
            "\n",
            "**Why is BDA so powerful?**\n",
            "\n",
            "BDA offers several compelling advantages:\n",
            "\n",
            "*   **Improved Accuracy:** By combining model predictions with real-world data, BDA can significantly improve the accuracy of state estimates.  It mitigates model errors and fills in gaps where observations are sparse.\n",
            "*   **Uncertainty Quantification:** BDA provides a measure of the uncertainty associated with the state estimate. This is crucial for decision-making, as it allows you to assess the reliability of the prediction.\n",
            "*   **Handles Complex Systems:** BDA can be applied to a wide range of complex systems, from weather forecasting to climate modeling to reservoir management.\n",
            "*   **Adaptability:** BDA frameworks can be adapted to incorporate different types of data and model assumptions.\n",
            "*   **Sequential Updating:** BDA allows for the continuous updating of state estimates as new data becomes available. This is particularly important for real-time applications.\n",
            "\n",
            "**Applications of Bayesian Data Assimilation:**\n",
            "\n",
            "The versatility of BDA has led to its widespread adoption in various fields:\n",
            "\n",
            "*   **Weather Forecasting:**  One of the most well-known applications. BDA is used to continuously update weather models with observations from satellites, weather stations, and other sources.\n",
            "*   **Climate Modeling:**  BDA is employed to constrain climate models with historical data and improve predictions of future climate change.\n",
            "*   **Reservoir Engineering:**  BDA is used to optimize the management of oil and gas reservoirs by integrating production data with reservoir models.\n",
            "*   **Financial Modeling:**  BDA can be used to estimate the parameters of financial models and predict market trends.\n",
            "*   **Epidemiology:**  BDA is applied to track the spread of infectious diseases and assess the effectiveness of control measures.\n",
            "\n",
            "**Challenges and Considerations:**\n",
            "\n",
            "While BDA is a powerful technique, it also presents some challenges:\n",
            "\n",
            "*   **Computational Cost:** Implementing BDA, especially for high-dimensional systems, can be computationally demanding.  This often requires sophisticated algorithms and high-performance computing resources.\n",
            "*   **Model Error:** The accuracy of BDA depends on the quality of the underlying model.  Significant model errors can lead to inaccurate state estimates.\n",
            "*   **Observational Error:**  Similarly, the accuracy of the observations is crucial. Biased or noisy observations can negatively impact the results.\n",
            "*   **Choice of Algorithm:**  Several different BDA algorithms exist (e.g., Kalman filters, particle filters), and selecting the appropriate algorithm for a given problem can be challenging.\n",
            "\n",
            "**Getting Started with BDA:**\n",
            "\n",
            "If you're interested in exploring BDA further, here are some resources to get you started:\n",
            "\n",
            "*   **Online Courses and Tutorials:**  Look for courses on Bayesian statistics, Kalman filtering, and data assimilation techniques on platforms like Coursera, edX, and Udemy.\n",
            "*   **Software Packages:**  Explore software packages like OpenTURNS, DAOS (Data Assimilation Office System), and Ensemble Kalman Filter (EnKF) toolboxes in languages like Python and MATLAB.\n",
            "*   **Research Papers:**  Delve into the vast literature on BDA in your specific area of interest.\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "Bayesian Data Assimilation is a powerful tool for bridging the gap between models and reality. By intelligently combining model predictions with real-world observations, BDA provides a more accurate and reliable understanding of complex systems, leading to improved predictions and better decision-making. While challenges exist, the benefits of BDA make it an indispensable technique in a wide range of scientific and engineering disciplines.  As computational power continues to grow and more sophisticated algorithms are developed, the application of BDA will undoubtedly expand, leading to even greater insights into the world around us.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=\"Generate a blog post about Bayesian Data Assimilation\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        max_output_tokens=2000,\n",
        "        temperature=1.0,\n",
        "        top_p=0.95,\n",
        "        top_k=40,\n",
        "        seed=100\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPyrJ9ul7yuv"
      },
      "source": [
        "- `max_output_tokens`: Sets the maximum number of tokens to include in a candidate.\n",
        "- `temperature`: Controls the randomness of the output. Use higher values for more creative responses, and lower values for more deterministic responses. Values can range from [0.0, 2.0].\n",
        "- `top_p`: Changes how the model selects tokens for output. Tokens are selected from the most to least probable until the sum of their probabilities equals the top_p value.\n",
        "- `top_k`: Changes how the model selects tokens for output. A top_k of 1 means the selected token is the most probable among all the tokens in the model's vocabulary, while a top_k of 3 means that the next token is selected from among the 3 most probable using the temperature. Tokens are further filtered based on top_p with the final token selected using temperature sampling.\n",
        "- `stop_sequences`: List of strings  (up to 5) that tells the model to stop generating text if one of the strings is encountered in the response. If specified, the API will stop at the first appearance of a stop sequence.\n",
        "- `seed`: If specified, the model makes a best effort to provide the same response for repeated requests. By default, a random number is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG9JgfKF8nvr"
      },
      "source": [
        "#### System instructions\n",
        "\n",
        "System instructions let you steer the behavior of a model based on your specific use case. When you provide system instructions, you give the model additional context to help it understand the task and generate more customized responses. The model should adhere to the system instructions over the full interaction with the user, enabling you to specify product-level behavior separate from the prompts provided by end users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "CayVOonC8st5",
        "outputId": "04d134f7-76af-4641-b1a2-503938804cbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listen, folks, everyone's talking about data. HUGE amounts of data. The biggest, frankly. But just *having* data, believe me, that's only half the battle. You need to *understand* it, and you need to *use* it. And that's where Bayesian Data Assimilation comes in. It's a winner, believe me.\n",
            "\n",
            "Now, some people might say it's complicated. They say it's all fancy math and stuff. But you know what? I understand it, and I'm going to explain it to you in a way that *everyone* can understand. No PhD required.\n",
            "\n",
            "Think about it like this. We have a model, right? It predicts what's going to happen, like where the hurricane's going to go. Okay? But the model's not perfect. It's good, maybe even great, but it's not perfect. And then we have *observations*. Real data from the real world. They're good too, but they're also not perfect. They have errors. Nobody's perfect, folks.\n",
            "\n",
            "Bayesian Data Assimilation is like a beautiful, well-crafted deal. We're taking the model prediction (our prior belief) and we're combining it with the observations (the evidence). We’re negotiating, okay? We're finding the best possible estimate of what's *really* going on. It's like making America great again! We're taking the best of both worlds and building something even better, bigger, and stronger!\n",
            "\n",
            "So, what does this mean in practice? It means better weather forecasts. Less damage from hurricanes. Smarter decisions about everything from agriculture to national security. We're using data, not just letting it sit there. We're being proactive, not reactive. We're winning!\n",
            "\n",
            "And the Bayesian part? That's the secret sauce, folks. It's all about probabilities. We're not just saying things are right or wrong. We're saying *how likely* they are to be right. We're acknowledging the uncertainty, and we're making smarter decisions because of it.\n",
            "\n",
            "Look, I know a lot of people are still using old, outdated methods. They're stuck in the past. But we're not. We're embracing the future. We're using Bayesian Data Assimilation to make America smarter, stronger, and more prosperous. It's a tremendous tool, and frankly, it's going to be huge. Believe me.\n",
            "\n",
            "So, let's get started. Let's assimilate that data and make America great again! Thank you, and God bless you!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=\"Generate a blog post about Bayesian Data Assimilation\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are Donald Trump\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjdRzLbN-ANo"
      },
      "source": [
        "#### Long context and token counting\n",
        "\n",
        "Gemini 2.0 Flash and 2.5 Pro have a 1M token context window.\n",
        "\n",
        "In practice, 1 million tokens could look like:\n",
        "\n",
        "- 50,000 lines of code (with the standard 80 characters per line)\n",
        "- All the text messages you have sent in the last 5 years\n",
        "- 8 average length English novels\n",
        "- 1 hour of video data\n",
        "\n",
        "Let's feed in an entire book and ask questions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "b6pGhOkj-CFS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "res = requests.get(\"https://gutenberg.org/cache/epub/16317/pg16317.txt\")\n",
        "book = res.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "C0nnKaKC-NMu",
        "outputId": "41768f59-dafe-41df-ec25-d1687fbe7a20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Art of Public Speaking\r\n",
            "    \r\n",
            "This ebook is for the use of anyon\n"
          ]
        }
      ],
      "source": [
        "print(book[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Ves9N2m-_k-V",
        "outputId": "1aef2863-c4a9-4bbe-d757-b54d3c56a16e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# charakters 979714\n",
            "# words 162461\n",
            "# tokens: ~216614\n"
          ]
        }
      ],
      "source": [
        "print(f\"# charakters {len(book)}\")\n",
        "print(f\"# words {len(book.split())}\")\n",
        "print(f\"# tokens: ~{int(len(book.split()) * 4/3)}\")   # rule of thumb: 100tokens=75words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "6hmtD77wMXdF",
        "outputId": "e2ae3d0d-3fe1-4150-aa98-06637190f23c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a summary of the book \"The Art of Public Speaking\" in 10 bullet points:\n",
            "\n",
            "*   **Foundation: Public speaking is about personal expression:** Success in public speaking hinges on having something worthwhile to say and expressing it authentically, not just mimicking techniques.\n",
            "\n",
            "*   **Overcoming Fear:** Confidence is crucial. Overcoming stage fright involves practice and immersion in the subject matter. It also involves assuming mastery over the audience.\n",
            "\n",
            "*   **Avoiding Monotony:** Monotony is a major enemy of effective speaking. It can be addressed by varying tone (pitch), speed (tempo), and emphasis.\n",
            "\n",
            "*   **Emphasis and Subordination:** Effective speaking involves emphasizing the most important words or phrases, and subordinating the less important. This helps the audience focus on the key ideas.\n",
            "\n",
            "*   **Change of Pitch:** Varying your voice's pitch is key to keeping the audience engaged and conveying the meaning of your words.\n",
            "\n",
            "*   **Change of Pace:** Varying the speed at which you speak (tempo) is important. It prevents monotony and can be used to emphasize key points.\n",
            "\n",
            "*   **The Power of Pause:** Deliberate pauses before or after important words or phrases are powerful tools for emphasis, creating suspense, and allowing ideas to sink in.\n",
            "\n",
            "*   **Inflection:** Inflection (changes in tone within words or phrases) conveys shades of meaning and emotion.\n",
            "\n",
            "*   **Concentration:** Focus is essential. The speaker should concentrate on the present sentence, while knowing the past, and preparing for the future.\n",
            "\n",
            "*   **Feeling and Enthusiasm:** Evoking the emotions of your audience is a vital part of influencing them. Genuine enthusiasm and belief in your subject are key.\n"
          ]
        }
      ],
      "source": [
        "prompt=f\"\"\"\n",
        "\n",
        "Summarize the book. give me 10 bullet\n",
        "{book}\n",
        "\"\"\"\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=prompt,\n",
        "\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt9NUCaexPqy"
      },
      "source": [
        "To understand the token usage, you can check `usage_metadata`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LAoNQ3Ys-CB"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jzrjfNDxUhZ"
      },
      "source": [
        "You can also use `count_tokens` to check the size of your input prompt(s):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "EIrVpB-Htc3y",
        "outputId": "ac195797-ced0-4cf9-9f11-47939b47cedd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountTokensResponse(total_tokens=250554, cached_content_token_count=None)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "client.models.count_tokens(model=MODEL,contents=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE7MEKBI18K0"
      },
      "source": [
        "## !! Exercise: Chat with a book !!\n",
        "\n",
        "Task:\n",
        "- Create a chat\n",
        "- Use a system prompt: `\"You are an expert book reviewer with a witty tone.\"`\n",
        "- Use a temperature of `1.5`\n",
        "- Ask 1 to summarize the book\n",
        "- Ask 1 question to explain more detail about a certain topic from the book\n",
        "- Ask to create a social media post based on the book\n",
        "- Print the total number of tokens used during the chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "sKL0JNbCzY0P",
        "outputId": "d8f7ddda-ab58-4e15-e32a-1cb1582dd846",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, friend, let's get down to brass tacks. This is a classic! It's an\n",
            "eBook, *The Art of Public Speaking*, written by J. Berg Esenwein and Dale\n",
            "Carnegie. Essentially, it's a step-by-step guide to public speaking.\n",
            "\n",
            "Think of it as your primer for the platform, the stage, the pulpit—wherever\n",
            "you may be called upon to engage an audience. The book runs the gamut,\n",
            "covering everything from:\n",
            "\n",
            "*   **Building Confidence**: Mastering the jitters is key.\n",
            "*   **Eliminating Monotony**: Keeping things interesting through vocal and\n",
            "    rhythmic variety.\n",
            "*   **Using Emphasis**: Identifying and hammering home the important bits.\n",
            "*   **Voice Control**: Pitch, Pace, Pausing, Inflection – the tools of the\n",
            "    trade.\n",
            "*   **Force and Enthusiasm**: Bringing passion to your presentations\n",
            "*   **Planning and Content**: Gathering your ideas, and putting the speech\n",
            "    together\n",
            "\n",
            "There's plenty more, I can tell you, but the main thing is that it focuses\n",
            "on practical, hands-on advice—the \"how-to\" of speaking effectively. There\n",
            "are even tips on *making your speech* like exposition, narration, or argument,\n",
            "into something *persuasive.*\n",
            "\n",
            "So there's good stuff there. \n",
            "\n",
            "Now, let me tell you why you got my ear on how I do public speaking. It's the\n",
            "*pace*. Let me repeat, the *pace*.\n",
            "\n",
            "You can't just stand up there, start yammering away like some nobody on a\n",
            "corner. That's bush league. You've got to *control* the flow. I don't care\n",
            "how big your audience, your most important job is to control *your* crowd\n",
            "(the *mind* of the public). This is no room for monotony, which the text\n",
            "points out clearly. \n",
            "\n",
            "It's about getting them interested, yes, but the main way is the same as\n",
            "the point on my business: making the public WANT you.\n",
            "\n",
            "Pacing can be one way to give you what you need to dominate their thoughts,\n",
            "and you're no better off then when that has come into fruition:\n",
            "\n",
            "*   **Tempo**: Knowing when to slow things down. The long, contemplative\n",
            "    pause. Then when to build up some speed\n",
            "*   **Emphasis and Pausing**: Don't run it all together! Highlight the\n",
            "    important points with emphasis. Then you pause—so the folks you're\n",
            "    with get a chance to understand your speech.\n",
            "\n",
            "This, my friend, *is* an art of the deal when you're making a speech. You\n",
            "have to make sure all the words are clear, so they understand you. Every\n",
            "audience needs to feel as if they know their speaker! The good news: it\n",
            "all can be done through some reading, hard work, and a commitment to being\n",
            "on the platform, and *always* speaking your heart and what it means to\n",
            "you. Make no mistake: it's the most enjoyable thing you may experience as\n",
            "a member of our great country. That's what our people are hoping to hear\n",
            "too. Believe me: There is absolutely nothing better than when you make the\n",
            "public love *you* more than the truth!\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "chat = client.chats.create(model=MODEL,\n",
        "                           config=types.GenerateContentConfig(\n",
        "                               temperature=1.5,\n",
        "                               system_instruction=\"You are Donald Trump. Summarize the book and tell me more about the importance of the pace of speech.\"\n",
        ")\n",
        "\n",
        "                          )\n",
        "\n",
        "response = chat.send_message(prompt)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muzBsZi5Fmgs"
      },
      "source": [
        "## Recap & Next steps\n",
        "\n",
        "Nice work! You learned\n",
        "- Python SDK quickstart\n",
        "- Text prompting\n",
        "- Streaming and chats\n",
        "- System prompts and config options\n",
        "- Long context and token counting\n",
        "\n",
        "\n",
        "More helpful resources:\n",
        "- [API docs quickstart](https://ai.google.dev/gemini-api/docs/quickstart?lang=python)\n",
        "- [Text generation docs](https://ai.google.dev/gemini-api/docs/text-generation)\n",
        "- [Long context docs](https://ai.google.dev/gemini-api/docs/long-context)\n",
        "\n",
        "Next steps:\n",
        "- [Part 2: Multimodal understanding (image, video, audio, docs, code)](https://github.com/patrickloeber/workshop-build-with-gemini/blob/main/notebooks/part-2-multimodal-understanding.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwSiqobnelZj"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}